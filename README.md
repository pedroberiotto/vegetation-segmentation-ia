# Vegetation Segmentation â€“ Desafio de IA

Este repositÃ³rio implementa um pipeline completo para **segmentaÃ§Ã£o de vegetaÃ§Ã£o em imagens aÃ©reas/ortomosaicos**, seguindo as 4 etapas solicitadas no desafio:

1. Quebra do ortomosaico em blocos (tiles)
2. GeraÃ§Ã£o de dataset (binarizaÃ§Ã£o)
3. Treinamento de uma Rede Neural (CNN â€“ FCN)
4. InferÃªncia do modelo em imagens nÃ£o vistas

---

## ğŸ“ Estrutura do RepositÃ³rio

```
vegetation-segmentation/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Ortomosaicos originais (TIFF)
â”‚   â”œâ”€â”€ tiles/               # Blocos gerados (Etapa 1)
â”‚   â”œâ”€â”€ masks/               # MÃ¡scaras binÃ¡rias (Etapa 2)
â”‚   â”œâ”€â”€ inference_inputs/    # Imagens externas para inferÃªncia
â”‚   â””â”€â”€ inference_outputs/   # Resultados da inferÃªncia
â”‚
â”œâ”€â”€ models/                  # Modelos treinados (.h5)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ divide_orthomosaic.py
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â””â”€â”€ binarize_images.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train_model.py
â”‚   â””â”€â”€ inference/
â”‚       â””â”€â”€ model_inference.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ validate_dataset.py
â”‚   â”œâ”€â”€ count_mask_values.py
â”‚   â””â”€â”€ run_pipeline.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“‚ ObservaÃ§Ã£o sobre os Dados 

As pastas dentro de `data/` estÃ£o intencionalmente vazias neste repositÃ³rio.

Devido Ã s **restriÃ§Ãµes de tamanho do Git/GitHub para arquivos grandes (ex.: ortomosaicos e imagens TIFF)**, os dados de entrada e saÃ­da nÃ£o foram versionados.

Para executar o pipeline corretamente, coloque o arquivo de ortomosaico (ex.: `orthomosaic.tif`) em `data/raw/`.
   
---

## âš™ï¸ Ambiente

### Criar ambiente virtual

```bash
# macOS / Linux
python3 -m venv .venv
source .venv/bin/activate

# Windows (PowerShell)
py -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### Instalar dependÃªncias

```bash
pip install -r requirements.txt
```
---

### ğŸ§© Etapa 1 â€” Quebra do Ortomosaico

```bash
python src/preprocessing/divide_orthomosaic.py \
  --input data/raw/orthomosaic.tif \
  --output data/tiles/ \
  --tile_size 512
```

> **Nota:** `--tile_size` Ã© **opcional** (padrÃ£o: 512).

**Resultado:** imagens menores (tiles) em `data/tiles/`.

---

## ğŸŒ± Etapa 2 â€” GeraÃ§Ã£o de Dataset (BinarizaÃ§Ã£o)

Gera as mÃ¡scaras de segmentaÃ§Ã£o (ground truth) a partir dos tiles RGB.

* Pixels com vegetaÃ§Ã£o â†’ **1**
* Pixels sem vegetaÃ§Ã£o â†’ **0**

A binarizaÃ§Ã£o utiliza o Ã­ndice **ExG (Excess Green Index)** com limiarizaÃ§Ã£o automÃ¡tica (Otsu).

**Script:** `src/dataset/binarize_images.py`

**Comando:**

```bash
python src/dataset/binarize_images.py \
  --input data/tiles/ \
  --output data/masks/
```

**Resultado:** mÃ¡scaras em escala de cinza (0/1) em `data/masks/`.

---

## ğŸ” ValidaÃ§Ã£o do Dataset

Antes do treinamento, o dataset Ã© validado automaticamente.

### 1. ValidaÃ§Ã£o estrutural

Verifica:

* CorrespondÃªncia 1â€“paraâ€“1 entre tiles e mÃ¡scaras
* DimensÃµes iguais
* MÃ¡scaras em escala de cinza
* Valores apenas {0,1}

**Script:** `scripts/validate_dataset.py`

```bash
python scripts/validate_dataset.py \
  --rgb data/tiles/ \
  --masks data/masks/
```

### 2. EstatÃ­sticas do dataset

Conta quantos pixels pertencem a cada classe (0 e 1) para anÃ¡lise de balanceamento.

**Script:** `scripts/count_mask_values.py`

```bash
python scripts/count_mask_values.py \
  --masks data/masks/
```

---

## ğŸ¤– Etapa 3 â€” Treinamento do Modelo

Foi utilizada uma **CNN do tipo FCN (Fully Convolutional Network)** para segmentaÃ§Ã£o binÃ¡ria:

* Arquitetura encoderâ€“decoder simples
* SaÃ­da pixel a pixel
* FunÃ§Ã£o de perda: `binary_crossentropy`

**Script:** `src/training/train_model.py`

**Comando (conforme enunciado):**

```bash
python src/training/train_model.py \
  --rgb data/tiles/ \
  --groundtruth data/masks/ \
  --modelpath models/vegetation_model.h5
```

**Resultado:** modelo treinado salvo em `models/vegetation_model.h5`.

---

## ğŸ”® Etapa 4 â€” InferÃªncia do Modelo

Aplica o modelo treinado em uma **imagem RGB nÃ£o utilizada no treinamento**, avaliando a capacidade de generalizaÃ§Ã£o.

A interface de execuÃ§Ã£o segue **exatamente o comando solicitado no enunciado**:

```bash
python model_inference.py --rgb </path/to/image.png> --modelpath </path/to/model.h5> --output </path/to/segmented/image.png>
```

No projeto:

**Script:** `src/inference/model_inference.py`

```bash
python src/inference/model_inference.py \
  --rgb data/inference_inputs/teste.jpg \
  --modelpath models/vegetation_model.h5 \
  --output data/inference_outputs/teste_segmentado.png
```

**Resultado:** imagem segmentada em escala de cinza:

* **0 (preto)** â†’ nÃ£o vegetaÃ§Ã£o
* **255 (branco)** â†’ vegetaÃ§Ã£o

---

## ğŸš€ Pipeline Automatizada

AlÃ©m da execuÃ§Ã£o individual de cada etapa, foi implementada uma pipeline que executa todo o fluxo de ponta a ponta:

1. Limpeza de diretÃ³rios (`tiles`, `masks`, `inference_outputs`)
2. DivisÃ£o do ortomosaico
3. BinarizaÃ§Ã£o
4. ValidaÃ§Ã£o do dataset
5. EstatÃ­sticas de classes
6. Treinamento do modelo
7. InferÃªncia

**Script:** `scripts/run_pipeline.py`

**Comando:**

```bash
python scripts/run_pipeline.py \
  --orthomosaic data/raw/orthomosaic.tif \
  --inference_image data/inference_inputs/teste.jpg \
  --tile_size 128 \
  --modelpath models/vegetation_model.h5
```

A pipeline **respeita integralmente a interface exigida na Etapa 4**, apenas automatizando sua execuÃ§Ã£o.

---

## ğŸ“Š GeneralizaÃ§Ã£o do Modelo

O modelo foi testado com imagens externas (capturadas por drones ou obtidas de bancos pÃºblicos), conforme sugerido no enunciado.

ObservaÃ§Ãµes tÃ­picas:

* Boa detecÃ§Ã£o em regiÃµes com vegetaÃ§Ã£o densa
* LimitaÃ§Ãµes em Ã¡reas com vegetaÃ§Ã£o esparsa ou baixo contraste
* Sensibilidade a artefatos grÃ¡ficos (linhas, sombras)

Esses testes demonstram **capacidade de generalizaÃ§Ã£o**, bem como oportunidades de melhoria com dados multiespectrais ou rÃ³tulos manuais.
